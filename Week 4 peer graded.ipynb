{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f34b440",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "\n",
    "Provide a brief overview of the project.\n",
    "Describe the problem you are addressing.\n",
    "State the goals and objectives of the analysis.\n",
    "\n",
    "### 2. Data Description\n",
    "\n",
    "Introduce the dataset.\n",
    "Describe the features and their meanings.\n",
    "Discuss the target variable.\n",
    "Mention the source of the data, if applicable.\n",
    "\n",
    "### 3. EDA (Exploratory Data Analysis)\n",
    "\n",
    "Import libraries and load the dataset.\n",
    "Display basic statistics (e.g., mean, median, standard deviation).\n",
    "Visualize the data using plots and graphs:\n",
    "Histograms, box plots, scatter plots, etc.\n",
    "Examine data distributions and relationships.\n",
    "Handle missing data and perform data preprocessing if needed.\n",
    "\n",
    "### 4. Data Preprocessing\n",
    "\n",
    "Data cleaning (e.g., handling missing values, outliers).\n",
    "Feature engineering (if necessary).\n",
    "Encoding categorical variables.\n",
    "Train-test split for model evaluation.\n",
    "\n",
    "### 5. Model Building and Training\n",
    "\n",
    "Define the machine learning algorithm(s) you will use.\n",
    "Set up the model(s) with appropriate hyperparameters.\n",
    "Train the model(s) on the training data.\n",
    "Evaluate model performance on the validation set using relevant metrics.\n",
    "Hyperparameter tuning (if applicable).\n",
    "\n",
    "### 6. Results\n",
    "\n",
    "Present the results of your analysis.\n",
    "Display key performance metrics (e.g., accuracy, precision, recall, F1-score).\n",
    "Visualize results using relevant plots (e.g., ROC curve, confusion matrix).\n",
    "Compare the performance of different models if applicable.\n",
    "\n",
    "### 7. Discussion and Conclusion\n",
    "\n",
    "Interpret the results and their significance.\n",
    "Discuss any insights or patterns observed during the analysis.\n",
    "Address any limitations of the analysis.\n",
    "Provide recommendations or next steps for further research.\n",
    "Conclude with a summary of the project's outcomes and contributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6c58cf",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA) â€” Inspect, Visualize and Clean the Data\n",
    "First, we will import necessary libraries and load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import libraries for linear algebra, data processing and dictionaries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# libraries for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# libraries for NLP preprocessing\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# libraries for NN models creation\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from keras.initializers import Constant\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#!pip3 install bert-for-tf2\n",
    "from bert import bert_tokenization\n",
    "# load the datasets\n",
    "train_df = pd.read_csv('nlp-getting-started/train.csv')\n",
    "test_df = pd.read_csv('nlp-getting-started/test.csv')\n",
    "submission = pd.read_csv('nlp-getting-started/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d3db05",
   "metadata": {},
   "source": [
    "### Data inspection and visualization\n",
    "Check data information, data types and missing values.\n",
    "\n",
    "We can see that there are missing values in \"keyword\" and \"location\" columns both in training and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0520e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()\n",
    "# Obtain the number of disaster and not disaster tweets\n",
    "disaster = train_df[train_df['target'] == 1].shape[0]\n",
    "not_disaster = train_df[train_df['target'] == 0].shape[0]\n",
    "print(f'There are {disaster} disaster tweets and {not_disaster} general tweets in the training dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6736a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create corpus\n",
    "def create_corpus(df, target='opt'):\n",
    "    corpus = []\n",
    "    if target != 'opt':\n",
    "        for tweet in df[df['target']==target]['text']:\n",
    "            words = [i for i in word_tokenize(tweet.lower()) if i not in stop]\n",
    "            corpus.append(words)\n",
    "    else:\n",
    "        for tweet in df['text']:\n",
    "            words = [i for i in word_tokenize(tweet.lower()) if i not in stop]\n",
    "            corpus.append(words)\n",
    "    return corpus \n",
    "    \n",
    "# create dictionary and visualize barplot\n",
    "dic = defaultdict(int)\n",
    "for tweet in create_corpus(train_df, 0):\n",
    "    for word in tweet:\n",
    "        dic[word] += 1\n",
    "\n",
    "top = sorted(dic.items(),key=lambda item:item[1], reverse=True)[:10]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "x,y=zip(*top)\n",
    "plt.bar(x,y)\n",
    "plt.title('Most frequent words in general tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f1b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c24a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ad43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a830165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
